{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your keys/secrets as strings in the following fields\n",
    "# credentials = {}\n",
    "# credentials['client_id'] = 'Tt3sc9zHX1U4Pg'\n",
    "# credentials['client_secret'] = 'Tl_rWZZtVo0k46FFkM2i0BBCWQM'\n",
    "# credentials['user_agent'] = 'Scraping_data'\n",
    "# credentials['username'] = '311Sheetal'\n",
    "# credentials['password'] = 'Reddit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the credentials object to file\n",
    "# with open(\"reddit_credentials.json\", \"w\") as file:\n",
    "#           json.dump(credentials, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from json file\\n\n",
    "with open(\"reddit_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = creds['client_id'],\n",
    "                     client_secret = creds['client_secret'],\n",
    "                     user_agent = creds['user_agent'],\n",
    "                     username = creds['username'],\n",
    "                     password = creds['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Reddit Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = {'republicans' : ['Republican'],\n",
    "              'democrats': ['democrats']\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Posts and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_posts(reddit_instance, subreddits, limit_posts=100):\n",
    "    \n",
    "    subreddit_submissions_dict = {\"created\":[],\n",
    "                              \"title\":[],\n",
    "                              \"score\":[],\n",
    "                              \"post_id\": [],\n",
    "                              \"subreddit_id\": [],\n",
    "                              \"subreddit\" : [],\n",
    "                              \"author\" : [],\n",
    "                              \"title\":[],\n",
    "                              \"upvote_ratio\": [],\n",
    "                             \"body\": [],\n",
    "                             \"url\": [],\n",
    "                             \"num_comments\":[],\n",
    "                                 \"group\": []}\n",
    "\n",
    "    for i in subreddits:\n",
    "        for j in subreddits[i]:\n",
    "            subreddit = reddit.subreddit(j)\n",
    "            for submission in tqdm(subreddit.new(limit=limit_posts), total = limit_posts, file=sys.stdout):\n",
    "                if (not submission.banned_by is None) or (not submission.author is '[Deleted]') or (not submission.selftext == '[deleted]') or (not submission.selftext == '[removed]'):\n",
    "                    subreddit_submissions_dict['created'].append(submission.created)\n",
    "                    subreddit_submissions_dict['title'].append(submission.title)\n",
    "                    subreddit_submissions_dict['score'].append(submission.score)\n",
    "                    subreddit_submissions_dict['post_id'].append(submission.id)\n",
    "                    subreddit_submissions_dict['subreddit_id'].append(submission.subreddit_id)\n",
    "                    subreddit_submissions_dict['subreddit'].append(submission.subreddit)\n",
    "                    subreddit_submissions_dict['author'].append(submission.author)\n",
    "                    subreddit_submissions_dict['num_comments'].append(submission.num_comments)\n",
    "                    subreddit_submissions_dict['upvote_ratio'].append(submission.upvote_ratio)\n",
    "                    subreddit_submissions_dict['body'].append(submission.selftext)\n",
    "                    subreddit_submissions_dict['url'].append(submission.url)\n",
    "                    subreddit_submissions_dict['group'].append(i)\n",
    "                    \n",
    "    subreddit_data = pd.DataFrame(subreddit_submissions_dict)\n",
    "    _timestamp = subreddit_data[\"created\"].apply(get_date)\n",
    "    subreddit_data = subreddit_data.assign(timestamp = _timestamp)\n",
    "                    \n",
    "    return subreddit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_comments(reddit_instance,postids):\n",
    "    \n",
    "    comments_dict = {\n",
    "        \"created\": [],\n",
    "        \"comment_id\": [],\n",
    "        \"author\": [],\n",
    "        \"body\": [],\n",
    "        \"parent_id\":[],\n",
    "        \"submission_id\":[],\n",
    "        \"score\":[],\n",
    "        \"subreddit\":[],\n",
    "        \"subreddit_id\":[]\n",
    "    }\n",
    "\n",
    "    for postid in tqdm(postids, total = len(post_ids), file=sys.stdout):\n",
    "        submission = reddit_instance.submission(postid)\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        for comment in submission.comments.list():\n",
    "            if comment.body != \"[removed]\" and comment.author != None:\n",
    "                comments_dict['created'].append(comment.created_utc)\n",
    "                comments_dict['comment_id'].append(comment.id)\n",
    "                comments_dict['author'].append(comment.author)\n",
    "                comments_dict['body'].append(comment.body)\n",
    "                comments_dict['parent_id'].append(comment.parent_id)\n",
    "                comments_dict['submission_id'].append(postid)\n",
    "                comments_dict['score'].append(comment.score)\n",
    "                comments_dict['subreddit'].append(comment.subreddit)\n",
    "                comments_dict['subreddit_id'].append(comment.subreddit_id)\n",
    "            \n",
    "    return pd.DataFrame(comments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts File Exists!\n",
      "Read File!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('posts_group.csv'):\n",
    "    print(\"Posts File Exists!\")\n",
    "    subreddit_data = pd.read_csv('posts_group.csv')\n",
    "    print(\"Read File!\")\n",
    "else:\n",
    "    # pull posts from the group of subreddits\n",
    "    print(\"Pulling Subreddits!\")\n",
    "    limit_posts = 1000\n",
    "    subreddit_data = pull_posts(reddit, subreddits=subreddits, limit_posts= limit_posts)\n",
    "    subreddit_data.to_csv('posts_group.csv', index = False)\n",
    "    print(\"Pulled Posts from Subreddits!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling Comments from each Post!\n",
      "100%|██████████| 985/985 [19:12<00:00,  1.32it/s]\n",
      "100%|██████████| 976/976 [17:56<00:00,  1.03s/it]\n",
      "Pulled Comments from each Post!\n"
     ]
    }
   ],
   "source": [
    "# make dictionary of dataframes for each group\n",
    "if os.path.exists(\"comments_group.csv\"):\n",
    "    print(\"Comments File Exists!\")\n",
    "    subreddit_data = pd.read_csv('posts_group.csv')\n",
    "    print(\"Read File!\")\n",
    "\n",
    "else:\n",
    "    print(\"Pulling Comments from each Post!\")\n",
    "    groups_posts = {}\n",
    "    for i in subreddits:\n",
    "        post_ids = subreddit_data.loc[subreddit_data.group==i].post_id.values\n",
    "        groups_posts_df = fetch_comments(reddit, postids=post_ids)\n",
    "        groups_posts[i] = groups_posts_df  \n",
    "    # make a dataframe of users for each post thread\n",
    "    users_df = pd.concat(groups_posts, keys = groups_posts.keys()).reset_index().rename({'level_0':'group'},axis =\"columns\").drop(\"level_1\", axis = 1)\n",
    "    users_df.to_csv('comments_group.csv', index = False)\n",
    "    print(\"Pulled Comments from each Post!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make username dictionary for each group\n",
    "usernames = {}\n",
    "for i in subreddits:\n",
    "    usernames[i] = list()\n",
    "    \n",
    "for i in subreddits:\n",
    "    usernames[i].extend(list(set(users_df.loc[users_df['group'] == i]['author'].values)))\n",
    "    usernames[i].extend(list(set(subreddit_data.loc[subreddit_data['group'] == i]['author'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Get Comments and count of comments in different subreddits of a Particular User \n",
    "# df_republican_posts=pd.read_csv(\"RepublicanPosts.csv.zip/RepublicanPosts.csv\")\n",
    "# df_republican_comments=pd.read_csv(\"RepublicanComments.csv.zip\")\n",
    "# df_democrats_posts=pd.read_csv(\"democratsPosts.csv.zip\")\n",
    "# df_democrats_comments=pd.read_csv(\"democratsComments.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_users=[]\n",
    "# all_users.append(df_republican_posts['author'])\n",
    "# all_users.append(df_republican_comments['author'])\n",
    "# all_users.append(df_democrats_posts['author'])\n",
    "# all_users.append(df_democrats_comments['author'])\n",
    "# len(all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comments_dict = {\"user_id\":[],\n",
    "                    \"user\":[],\n",
    "                  \"comment\":[],\n",
    "                  \"subreddit\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican_users=[]\n",
    "democrat_users=[]\n",
    "count_democrats=0\n",
    "count_republican=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without user inclination\n",
    "for i in range(0,2):\n",
    "    for author in all_users[i]:\n",
    "        republican_users.append(author)\n",
    "        \n",
    "        \n",
    "for i in range(2,4):\n",
    "    for author in all_users[i]:\n",
    "        democrat_users.append(author)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(democrat_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(republican_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with user inclination\n",
    "for i in range(0,4):\n",
    "    for author in all_users[i]:\n",
    "        user = reddit.redditor(author)\n",
    "        \n",
    "        #get comments of that particular user\n",
    "        for c in user.comments.new(limit=None):\n",
    "            user_comments_dict['user_id'].append(user.id)\n",
    "            user_comments_dict['user'].append(user.name)\n",
    "            user_comments_dict['subreddit'].append(c.subreddit)\n",
    "            user_comments_dict['comment'].append(c.body)\n",
    "            #user_comments_dict['replies'].append(c.replies)\n",
    "            \n",
    "        user_comments = pd.DataFrame(user_comments_dict)\n",
    "        user_comments.to_csv(\"UserComments.csv\",mode='a',encoding = 'utf-8',header=False)\n",
    "        \n",
    "        count_df=user_comments.groupby('subreddit')['comment'].count().reset_index(name='counts')\n",
    "        newdf=count_df[count_df['subreddit']=='Republican']\n",
    "        \n",
    "        if len(newdf)!=0:\n",
    "            #print int(newdf['counts'])\n",
    "            count_republican=int(newdf['counts'])\n",
    "            \n",
    "            \n",
    "        newdf1=count_df[count_df['subreddit']=='democrats']\n",
    "        if len(newdf1)!=0:\n",
    "            count_democrats=int(newdf1['counts'])  \n",
    "            #print int(newdf1['counts'])\n",
    "            \n",
    "        if count_republican>=count_democrats:\n",
    "            republican_users.append(user)\n",
    "        else:\n",
    "            democrat_users.append(user)\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_df=user_comments.groupby('subreddit')['comment'].count().reset_index(name='counts')\n",
    "# newdf=count_df[count_df['subreddit']=='Republican']\n",
    "# print newdf\n",
    "# n=newdf['counts'].to_frame()\n",
    "# int(newdf['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user = reddit.redditor('tall_bacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print user\n",
    "# print user.id\n",
    "# print user.fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in user.comments.new(limit=None):\n",
    "#     user_comments_dict['user_id'].append(user.id)\n",
    "#     user_comments_dict['user'].append(user.name)\n",
    "#     user_comments_dict['subreddit'].append(c.subreddit)\n",
    "#     user_comments_dict['comment'].append(c.body)\n",
    "#     #user_comments_dict['replies'].append(c.replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_comments = pd.DataFrame(user_comments_dict)\n",
    "# user_comments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(user_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_df=user_comments.groupby('subreddit')['comment'].count()\n",
    "# count_df=count_df.reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(count_df)#.loc[1:3,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf=count_df[count_df['subreddit']=='Republican']\n",
    "# len(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=newdf['counts'][1]\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_df.loc[count_df['subreddit'] == 'The_Donald']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using Redittor.Stream\n",
    "#for c in user.stream.comments():\n",
    "#    print c.body\n",
    "#    print \"~\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of subscribers to a particular subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = reddit.subreddit('Republican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name.subscribers  #the names of the subscribers is private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
