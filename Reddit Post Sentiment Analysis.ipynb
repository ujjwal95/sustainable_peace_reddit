{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from reddit_helpers.text_processor import reddit_text_preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from json file\\n\n",
    "with open(\"reddit_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 'Tt3sc9zHX1U4Pg',\n",
       " 'client_secret': 'Tl_rWZZtVo0k46FFkM2i0BBCWQM',\n",
       " 'user_agent': 'Scraping_data',\n",
       " 'username': '311Sheetal',\n",
       " 'password': 'Reddit'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = creds['client_id'],\n",
    "                     client_secret = creds['client_secret'],\n",
    "                     user_agent = creds['user_agent'],\n",
    "                     username = creds['username'],\n",
    "                     password = creds['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_comments(reddit_instance, pd_posts, users):\n",
    "    \n",
    "    comments_dict = {\n",
    "        \"created\": [],\n",
    "        \"comment_id\": [],\n",
    "        \"author\": [],\n",
    "        \"body\": [],\n",
    "        \"parent_id\":[],\n",
    "        \"submission_id\":[],\n",
    "        \"score\":[],\n",
    "        \"subreddit\":[],\n",
    "        \"subreddit_id\":[],\n",
    "        \"submission_group\":[],\n",
    "        \"comment_group\":[]\n",
    "    }\n",
    "\n",
    "#     submission = reddit_instance.submission(list(pd_posts['post_id'].values))\n",
    "    for postid in tqdm(list(pd_posts['post_id'].values)):\n",
    "        submission = reddit_instance.submission(postid)\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        for comment in submission.comments.list():\n",
    "            if comment is not None:\n",
    "                if comment.author is not None:\n",
    "                    if comment.author.name != \"AutoModerator\":\n",
    "                        if comment.author.name in users['user'].values:\n",
    "                            comments_dict['created'].append(comment.created_utc)\n",
    "                            comments_dict['comment_id'].append(comment.id)\n",
    "                            comments_dict['author'].append(comment.author)\n",
    "                            comments_dict['body'].append(comment.body)\n",
    "                            comments_dict['parent_id'].append(comment.parent_id)\n",
    "                            comments_dict['submission_id'].append(postid)\n",
    "                            comments_dict['score'].append(comment.score)\n",
    "                            comments_dict['subreddit'].append(comment.subreddit)\n",
    "                            comments_dict['subreddit_id'].append(comment.subreddit_id)\n",
    "                            comments_dict['submission_group'].append(pd_posts.loc[pd_posts['post_id']==postid]['group'].values)\n",
    "                            comments_dict['comment_group'].append(users.loc[users['user']==comment.author.name]['subreddit'].values)\n",
    "                        \n",
    "    comments_info = pd.DataFrame(comments_dict)\n",
    "    comments_info.comment_group = comments_info.comment_group.apply(lambda x: x[0])\n",
    "    comments_info.submission_group = comments_info.submission_group.apply(lambda x: x[0])\n",
    "    \n",
    "    return comments_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user ids for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./user_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_subreddits = ['politics', \n",
    "                       'politicaldiscussion',\n",
    "                       'politicalfactchecking',\n",
    "                       'neutralpolitics',\n",
    "                       'moderatepolitics',\n",
    "                       'centrist',\n",
    "                       'ask_Politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3379it [6:55:38, 11.53s/it]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"submissions_data.csv\"):\n",
    "    print(\"Submissions File Exists!\")\n",
    "    subreddit_data = pd.read_csv('submissions_data.csv')\n",
    "    print(\"Read File!\")\n",
    "\n",
    "else:\n",
    "    a = 0 \n",
    "    subreddit_submissions_dict = {\"created\":[],\n",
    "                             \"title\":[],\n",
    "                             \"score\":[],\n",
    "                             \"post_id\": [],\n",
    "                             \"subreddit_id\": [],\n",
    "                             \"subreddit\" : [],\n",
    "                             \"author\" : [],\n",
    "                             \"title\":[],\n",
    "                             \"upvote_ratio\": [],\n",
    "                             \"body\": [],\n",
    "                             \"url\": [],\n",
    "                             \"num_comments\":[],\n",
    "                             \"group\": []}\n",
    "\n",
    "    for i in tqdm(users.iterrows()):\n",
    "        user = reddit.redditor(i[1]['user'])\n",
    "        try:\n",
    "            id = user.id\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        for submission in user.submissions.new(limit=None):\n",
    "            if (not submission.banned_by is None) or (not submission.author is '[Deleted]') or (not submission.selftext == '[deleted]') or (not submission.selftext == '[removed]'):\n",
    "\n",
    "                if ' '.join([ word.strip().lower() for word in submission.subreddit.display_name.split()]) in conflict_subreddits:\n",
    "                    subreddit_submissions_dict['created'].append(submission.created)\n",
    "                    subreddit_submissions_dict['title'].append(submission.title)\n",
    "                    subreddit_submissions_dict['score'].append(submission.score)\n",
    "                    subreddit_submissions_dict['post_id'].append(submission.id)\n",
    "                    subreddit_submissions_dict['subreddit_id'].append(submission.subreddit_id)\n",
    "                    subreddit_submissions_dict['subreddit'].append(submission.subreddit)\n",
    "                    subreddit_submissions_dict['author'].append(submission.author)\n",
    "                    subreddit_submissions_dict['num_comments'].append(submission.num_comments)\n",
    "                    subreddit_submissions_dict['upvote_ratio'].append(submission.upvote_ratio)\n",
    "                    subreddit_submissions_dict['body'].append(submission.selftext)\n",
    "                    subreddit_submissions_dict['url'].append(submission.url)\n",
    "                    subreddit_submissions_dict['group'].append(i[1]['subreddit'])\n",
    "\n",
    "    #     if a == 50:\n",
    "    #         break\n",
    "    #     a+=1\n",
    "\n",
    "    subreddit_data = pd.DataFrame(subreddit_submissions_dict)\n",
    "    _timestamp = subreddit_data[\"created\"].apply(get_date)\n",
    "    subreddit_data = subreddit_data.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Comments of a Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddit_data.to_csv(\"./submissions_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_posts = subreddit_data[['post_id', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9575/9575 [10:59:25<00:00,  6.29s/it]\n"
     ]
    }
   ],
   "source": [
    "comments_info = fetch_comments(reddit, pd_posts, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_info.to_csv(\"./final_comments.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_timestamp = comments_info[\"created\"].apply(get_date)\n",
    "comments_info = comments_info.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check linked users\n",
    "comments_info['linked_users'] = comments_info['body'].apply(lambda x: re.findall('/u/[A-Za-z0-9_-]+',x))\n",
    "# check linked subreddits\n",
    "comments_info['linked_subreddits'] = comments_info['body'].apply(lambda x: re.findall('r/[A-Za-z0-9_-]+',x))\n",
    "\n",
    "# remove numbers etc\n",
    "comments_info['processed_body'] = comments_info['body'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process text\n",
    "comments_info['processed_body'] = comments_info['processed_body'].apply(lambda x: reddit_text_preprocessing(x).replace_abbreviations().remove_short_words().lower_case().process_html().remove_urls().decode_text().stopwords_remove().stopwords_remove().lemmatize().text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use google language api\n",
    "\n",
    "# def gc_sentiment(text, credentials):  \n",
    "#     from google.cloud import language\n",
    "    \n",
    "#     client = language.LanguageServiceClient(credentials = credentials)\n",
    "#     document = language.types.Document(\n",
    "#             content=text,\n",
    "#             type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "#     annotations = client.analyze_sentiment(document=document)\n",
    "#     score = annotations.document_sentiment.score\n",
    "#     magnitude = annotations.document_sentiment.magnitude\n",
    "#     return score, magnitude\n",
    "\n",
    "# import os\n",
    "# from google.oauth2 import service_account\n",
    "# credentials = service_account.Credentials.from_service_account_file('./ecbm4040-up2138-b37eacd8e36c.json')\n",
    "# print('Credendtials from environ: {}'.format(os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')))\n",
    "\n",
    "# gc_results = [gc_sentiment(row, credentials) for row in tqdm(comments_info['processed_body'])]\n",
    "# gc_score, gc_magnitude = zip(*gc_results) # Unpacking the result into 2 lists\n",
    "# gc = list(zip(comments_info['processed_body'], gc_score, gc_magnitude))\n",
    "# columns = ['text', 'score', 'magnitude']\n",
    "# gc_df = pd.DataFrame(gc, columns = columns)\n",
    "\n",
    "# gc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting_comments = comments_info\n",
    "conflicting_comments = conflicting_comments[conflicting_comments.apply(lambda x: x['author'].name != \"AutoModerator\", axis=1)]\n",
    "conflicting_comments = conflicting_comments.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()\n",
    "conflicting_comments['compound_sentiment'] = conflicting_comments.apply(lambda x: sia.polarity_scores(x['body'])['compound'], axis = 1)\n",
    "conflicting_comments['negative_sentiment'] = conflicting_comments.apply(lambda x: sia.polarity_scores(x['body'])['neg'], axis = 1)\n",
    "conflicting_comments['positive_sentiment'] = conflicting_comments.apply(lambda x: sia.polarity_scores(x['body'])['pos'], axis = 1)\n",
    "conflicting_comments['neutral_sentiment'] = conflicting_comments.apply(lambda x: sia.polarity_scores(x['body'])['neu'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>created</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>submission_group</th>\n",
       "      <th>comment_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>linked_users</th>\n",
       "      <th>linked_subreddits</th>\n",
       "      <th>processed_body</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>negative_sentiment</th>\n",
       "      <th>positive_sentiment</th>\n",
       "      <th>neutral_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.432870e+09</td>\n",
       "      <td>crofq47</td>\n",
       "      <td>ljrdxyh</td>\n",
       "      <td>Should win Iowa and probably wins New Hampshir...</td>\n",
       "      <td>t1_crofp5c</td>\n",
       "      <td>37o59g</td>\n",
       "      <td>3</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2015-05-28 23:21:19</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>iowa probably win hampshire real test signific...</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.432868e+09</td>\n",
       "      <td>croeoyz</td>\n",
       "      <td>ljrdxyh</td>\n",
       "      <td>Well - the people have been there all along, R...</td>\n",
       "      <td>t1_croe8j8</td>\n",
       "      <td>37o59g</td>\n",
       "      <td>5</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2015-05-28 22:48:07</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>well peoriginal posterle along rand correctly ...</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.432868e+09</td>\n",
       "      <td>croen90</td>\n",
       "      <td>ljrdxyh</td>\n",
       "      <td>His record?  How so?</td>\n",
       "      <td>t1_croeh7y</td>\n",
       "      <td>37o59g</td>\n",
       "      <td>7</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2015-05-28 22:46:36</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>record significant</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.432870e+09</td>\n",
       "      <td>crofoyq</td>\n",
       "      <td>ljrdxyh</td>\n",
       "      <td>Agree that it is their responsibility.....whic...</td>\n",
       "      <td>t1_crofneg</td>\n",
       "      <td>37o59g</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2015-05-28 23:20:15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>agree reddit enhancement suiteponsibilithank g...</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.432869e+09</td>\n",
       "      <td>crofl4c</td>\n",
       "      <td>ljrdxyh</td>\n",
       "      <td>From one of the comments on the link:  \"left p...</td>\n",
       "      <td>t1_crof082</td>\n",
       "      <td>37o59g</td>\n",
       "      <td>23</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2015-05-28 23:16:48</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>comment linokay leave plenthank looriginal pos...</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       created comment_id   author  \\\n",
       "0      0  1.432870e+09    crofq47  ljrdxyh   \n",
       "1      1  1.432868e+09    croeoyz  ljrdxyh   \n",
       "2      2  1.432868e+09    croen90  ljrdxyh   \n",
       "3      3  1.432870e+09    crofoyq  ljrdxyh   \n",
       "4      4  1.432869e+09    crofl4c  ljrdxyh   \n",
       "\n",
       "                                                body   parent_id  \\\n",
       "0  Should win Iowa and probably wins New Hampshir...  t1_crofp5c   \n",
       "1  Well - the people have been there all along, R...  t1_croe8j8   \n",
       "2                               His record?  How so?  t1_croeh7y   \n",
       "3  Agree that it is their responsibility.....whic...  t1_crofneg   \n",
       "4  From one of the comments on the link:  \"left p...  t1_crof082   \n",
       "\n",
       "  submission_id  score subreddit subreddit_id submission_group comment_group  \\\n",
       "0        37o59g      3  politics     t5_2cneq       Republican    Republican   \n",
       "1        37o59g      5  politics     t5_2cneq       Republican    Republican   \n",
       "2        37o59g      7  politics     t5_2cneq       Republican    Republican   \n",
       "3        37o59g      2  politics     t5_2cneq       Republican    Republican   \n",
       "4        37o59g     23  politics     t5_2cneq       Republican    Republican   \n",
       "\n",
       "            timestamp linked_users linked_subreddits  \\\n",
       "0 2015-05-28 23:21:19           []                []   \n",
       "1 2015-05-28 22:48:07           []                []   \n",
       "2 2015-05-28 22:46:36           []                []   \n",
       "3 2015-05-28 23:20:15           []                []   \n",
       "4 2015-05-28 23:16:48           []                []   \n",
       "\n",
       "                                      processed_body  compound_sentiment  \\\n",
       "0  iowa probably win hampshire real test signific...              0.8176   \n",
       "1  well peoriginal posterle along rand correctly ...             -0.7096   \n",
       "2                                 record significant              0.0000   \n",
       "3  agree reddit enhancement suiteponsibilithank g...             -0.1531   \n",
       "4  comment linokay leave plenthank looriginal pos...             -0.2263   \n",
       "\n",
       "   negative_sentiment  positive_sentiment  neutral_sentiment  \n",
       "0               0.000               0.429              0.571  \n",
       "1               0.249               0.065              0.685  \n",
       "2               0.000               0.000              1.000  \n",
       "3               0.108               0.087              0.804  \n",
       "4               0.132               0.133              0.735  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflicting_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting_comments.to_csv(\"./conflicting_comments.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
