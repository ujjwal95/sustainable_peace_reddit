{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from reddit_helpers.text_processor import reddit_text_preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials from json file\\n\n",
    "with open(\"reddit_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 'Tt3sc9zHX1U4Pg',\n",
       " 'client_secret': 'Tl_rWZZtVo0k46FFkM2i0BBCWQM',\n",
       " 'user_agent': 'Scraping_data',\n",
       " 'username': '311Sheetal',\n",
       " 'password': 'Reddit'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = creds['client_id'],\n",
    "                     client_secret = creds['client_secret'],\n",
    "                     user_agent = creds['user_agent'],\n",
    "                     username = creds['username'],\n",
    "                     password = creds['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_comments(reddit_instance, pd_posts, users):\n",
    "    \n",
    "    comments_dict = {\n",
    "        \"created\": [],\n",
    "        \"comment_id\": [],\n",
    "        \"author\": [],\n",
    "        \"body\": [],\n",
    "        \"parent_id\":[],\n",
    "        \"submission_id\":[],\n",
    "        \"score\":[],\n",
    "        \"subreddit\":[],\n",
    "        \"subreddit_id\":[],\n",
    "        \"submission_group\":[],\n",
    "        \"commment_group\":[]\n",
    "    }\n",
    "\n",
    "#     submission = reddit_instance.submission(list(pd_posts['post_id'].values))\n",
    "    for postid in list(pd_posts['post_id'].values):\n",
    "        submission = reddit_instance.submission(postid)\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        for comment in submission.comments.list():\n",
    "            if comment is not None:\n",
    "                if comment.author is not None:\n",
    "                    if comment.author.name != \"AutoModerator\":\n",
    "                        if comment.author.name in users['user'].values:\n",
    "                            comments_dict['created'].append(comment.created_utc)\n",
    "                            comments_dict['comment_id'].append(comment.id)\n",
    "                            comments_dict['author'].append(comment.author)\n",
    "                            comments_dict['body'].append(comment.body)\n",
    "                            comments_dict['parent_id'].append(comment.parent_id)\n",
    "                            comments_dict['submission_id'].append(postid)\n",
    "                            comments_dict['score'].append(comment.score)\n",
    "                            comments_dict['subreddit'].append(comment.subreddit)\n",
    "                            comments_dict['subreddit_id'].append(comment.subreddit_id)\n",
    "                            comments_dict['submission_group'].append(pd_posts.loc[pd_posts['post_id']==postid]['group'].values)\n",
    "                            comments_dict['comment_group'].append(users.loc[users['user']==comment.author.name]['subreddit'].values)\n",
    "                        \n",
    "    comments_info = pd.DataFrame(comments_dict)\n",
    "    comments_info.comment_group = comments_info.comment_group.apply(lambda x: x[0])\n",
    "    comments_info.submission_group = comments_info.submission_group.apply(lambda x: x.values[0])\n",
    "    \n",
    "    return comments_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user ids for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('./user_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_subreddits = ['politics', \n",
    "                       'politicaldiscussion',\n",
    "                       'politicalfactchecking',\n",
    "                       'neutralpolitics',\n",
    "                       'moderatepolitics',\n",
    "                       'centrist',\n",
    "                       'ask_Politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "198it [08:46,  6.88s/it]\n"
     ]
    }
   ],
   "source": [
    "a = 0 \n",
    "subreddit_submissions_dict = {\"created\":[],\n",
    "                         \"title\":[],\n",
    "                         \"score\":[],\n",
    "                         \"post_id\": [],\n",
    "                         \"subreddit_id\": [],\n",
    "                         \"subreddit\" : [],\n",
    "                         \"author\" : [],\n",
    "                         \"title\":[],\n",
    "                         \"upvote_ratio\": [],\n",
    "                         \"body\": [],\n",
    "                         \"url\": [],\n",
    "                         \"num_comments\":[],\n",
    "                         \"group\": []}\n",
    "\n",
    "for i in tqdm(users.iterrows()):\n",
    "    user = reddit.redditor(i[1]['user'])\n",
    "\n",
    "    for submission in user.submissions.new(limit=100):\n",
    "        if (not submission.banned_by is None) or (not submission.author is '[Deleted]') or (not submission.selftext == '[deleted]') or (not submission.selftext == '[removed]'):\n",
    "            \n",
    "            if ' '.join([ word.strip().lower() for word in submission.subreddit.display_name.split()]) in conflict_subreddits:\n",
    "                subreddit_submissions_dict['created'].append(submission.created)\n",
    "                subreddit_submissions_dict['title'].append(submission.title)\n",
    "                subreddit_submissions_dict['score'].append(submission.score)\n",
    "                subreddit_submissions_dict['post_id'].append(submission.id)\n",
    "                subreddit_submissions_dict['subreddit_id'].append(submission.subreddit_id)\n",
    "                subreddit_submissions_dict['subreddit'].append(submission.subreddit)\n",
    "                subreddit_submissions_dict['author'].append(submission.author)\n",
    "                subreddit_submissions_dict['num_comments'].append(submission.num_comments)\n",
    "                subreddit_submissions_dict['upvote_ratio'].append(submission.upvote_ratio)\n",
    "                subreddit_submissions_dict['body'].append(submission.selftext)\n",
    "                subreddit_submissions_dict['url'].append(submission.url)\n",
    "                subreddit_submissions_dict['group'].append(i[1]['subreddit'])\n",
    "                \n",
    "#     if a == 50:\n",
    "#         break\n",
    "#     a+=1\n",
    "\n",
    "subreddit_data = pd.DataFrame(subreddit_submissions_dict)\n",
    "_timestamp = subreddit_data[\"created\"].apply(get_date)\n",
    "subreddit_data = subreddit_data.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Comments of a Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_posts = subreddit_data[['post_id', 'group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_info = fetch_comments(reddit, pd_posts, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "_timestamp = comments_info[\"created\"].apply(get_date)\n",
    "comments_info = comments_info.assign(timestamp = _timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check linked users\n",
    "comments_info['linked_users'] = comments_info['body'].apply(lambda x: re.findall('/u/[A-Za-z0-9_-]+',x))\n",
    "# check linked subreddits\n",
    "comments_info['linked_subreddits'] = comments_info['body'].apply(lambda x: re.findall('r/[A-Za-z0-9_-]+',x))\n",
    "\n",
    "# remove numbers etc\n",
    "comments_info['processed_body'] = comments_info['body'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process text\n",
    "comments_info['processed_body'] = comments_info['processed_body'].apply(lambda x: reddit_text_preprocessing(x).replace_abbreviations().remove_short_words().lower_case().process_html().remove_urls().decode_text().stopwords_remove().stopwords_remove().lemmatize().text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use google language api\n",
    "\n",
    "# def gc_sentiment(text, credentials):  \n",
    "#     from google.cloud import language\n",
    "    \n",
    "#     client = language.LanguageServiceClient(credentials = credentials)\n",
    "#     document = language.types.Document(\n",
    "#             content=text,\n",
    "#             type=language.enums.Document.Type.PLAIN_TEXT)\n",
    "#     annotations = client.analyze_sentiment(document=document)\n",
    "#     score = annotations.document_sentiment.score\n",
    "#     magnitude = annotations.document_sentiment.magnitude\n",
    "#     return score, magnitude\n",
    "\n",
    "# import os\n",
    "# from google.oauth2 import service_account\n",
    "# credentials = service_account.Credentials.from_service_account_file('./ecbm4040-up2138-b37eacd8e36c.json')\n",
    "# print('Credendtials from environ: {}'.format(os.environ.get('GOOGLE_APPLICATION_CREDENTIALS')))\n",
    "\n",
    "# gc_results = [gc_sentiment(row, credentials) for row in tqdm(comments_info['processed_body'])]\n",
    "# gc_score, gc_magnitude = zip(*gc_results) # Unpacking the result into 2 lists\n",
    "# gc = list(zip(comments_info['processed_body'], gc_score, gc_magnitude))\n",
    "# columns = ['text', 'score', 'magnitude']\n",
    "# gc_df = pd.DataFrame(gc, columns = columns)\n",
    "\n",
    "# gc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting_comments = comments_info.loc[comments_info['submission_group'] != comments_info['commment_group']]\n",
    "conflicting_comments = conflicting_comments[conflicting_comments.apply(lambda x: x['author'].name != \"AutoModerator\", axis=1)]\n",
    "conflicting_comments = conflicting_comments.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SIA()\n",
    "conflicting_comments['sentiment'] = conflicting_comments.apply(lambda x: sia.polarity_scores(x['body'])['compound'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>created</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>submission_group</th>\n",
       "      <th>commment_group</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>linked_users</th>\n",
       "      <th>linked_subreddits</th>\n",
       "      <th>processed_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1.542735e+09</td>\n",
       "      <td>ea41qcc</td>\n",
       "      <td>The_Best_Taker</td>\n",
       "      <td>New York Times already had her as the winner w...</td>\n",
       "      <td>t3_9ytcwe</td>\n",
       "      <td>9ytcwe</td>\n",
       "      <td>6</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>democrats</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2018-11-20 12:24:58</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>yorokay tinstant message already winner weeokays</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>1.542739e+09</td>\n",
       "      <td>ea47lrb</td>\n",
       "      <td>urbanlife78</td>\n",
       "      <td>With Democrats more in charge for the 2020 cen...</td>\n",
       "      <td>t1_ea3urnl</td>\n",
       "      <td>9ytcwe</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>democrats</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2018-11-20 13:33:44</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>de-mailoriginal contentrats charge census chan...</td>\n",
       "      <td>0.7579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>1.542741e+09</td>\n",
       "      <td>ea4ard0</td>\n",
       "      <td>urbanlife78</td>\n",
       "      <td>That is pretty funny, in a number of states, n...</td>\n",
       "      <td>t1_ea499ws</td>\n",
       "      <td>9ytcwe</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>democrats</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2018-11-20 14:13:30</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>pretthank fuck younny number state partisan co...</td>\n",
       "      <td>0.7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1.542749e+09</td>\n",
       "      <td>ea4lgxv</td>\n",
       "      <td>urbanlife78</td>\n",
       "      <td>I would really love to see the country move in...</td>\n",
       "      <td>t1_ea4l2sw</td>\n",
       "      <td>9ytcwe</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>democrats</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2018-11-20 16:29:02</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>would really love country move direction vote ...</td>\n",
       "      <td>0.9168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>1.542739e+09</td>\n",
       "      <td>ea47qh2</td>\n",
       "      <td>urbanlife78</td>\n",
       "      <td>And now we can all get 24 hour news feed strai...</td>\n",
       "      <td>t1_ea407z8</td>\n",
       "      <td>9ytcwe</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>democrats</td>\n",
       "      <td>Republican</td>\n",
       "      <td>2018-11-20 13:35:22</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>hour news fee strainstagramht echo chamber fil...</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       created comment_id          author  \\\n",
       "0     21  1.542735e+09    ea41qcc  The_Best_Taker   \n",
       "1     22  1.542739e+09    ea47lrb     urbanlife78   \n",
       "2     27  1.542741e+09    ea4ard0     urbanlife78   \n",
       "3     28  1.542749e+09    ea4lgxv     urbanlife78   \n",
       "4     30  1.542739e+09    ea47qh2     urbanlife78   \n",
       "\n",
       "                                                body   parent_id  \\\n",
       "0  New York Times already had her as the winner w...   t3_9ytcwe   \n",
       "1  With Democrats more in charge for the 2020 cen...  t1_ea3urnl   \n",
       "2  That is pretty funny, in a number of states, n...  t1_ea499ws   \n",
       "3  I would really love to see the country move in...  t1_ea4l2sw   \n",
       "4  And now we can all get 24 hour news feed strai...  t1_ea407z8   \n",
       "\n",
       "  submission_id  score subreddit subreddit_id submission_group commment_group  \\\n",
       "0        9ytcwe      6  politics     t5_2cneq        democrats     Republican   \n",
       "1        9ytcwe      1  politics     t5_2cneq        democrats     Republican   \n",
       "2        9ytcwe      2  politics     t5_2cneq        democrats     Republican   \n",
       "3        9ytcwe      2  politics     t5_2cneq        democrats     Republican   \n",
       "4        9ytcwe      0  politics     t5_2cneq        democrats     Republican   \n",
       "\n",
       "            timestamp linked_users linked_subreddits  \\\n",
       "0 2018-11-20 12:24:58           []                []   \n",
       "1 2018-11-20 13:33:44           []                []   \n",
       "2 2018-11-20 14:13:30           []                []   \n",
       "3 2018-11-20 16:29:02           []                []   \n",
       "4 2018-11-20 13:35:22           []                []   \n",
       "\n",
       "                                      processed_body  sentiment  \n",
       "0   yorokay tinstant message already winner weeokays     0.5859  \n",
       "1  de-mailoriginal contentrats charge census chan...     0.7579  \n",
       "2  pretthank fuck younny number state partisan co...     0.7717  \n",
       "3  would really love country move direction vote ...     0.9168  \n",
       "4  hour news fee strainstagramht echo chamber fil...     0.2263  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflicting_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting_comments.to_csv(\"./conflicting_comments.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
